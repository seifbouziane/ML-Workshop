{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVvcMuse75J2"
      },
      "source": [
        "\n",
        "# Classification on Wisconsin Breast Cancer data (with Python)\n",
        "\n",
        "\n",
        "In this notebook, we will explore some of the basic capabilities of Python's **scikit-learn** package for the data science's role to work with classification datasets. For numerical analysis of tabular data, we shall use the Pandas package, which includes specific data types and functions for working with two-dimensional tables of data in Python. The Pandas package offers a more convenient structure to work with data - the DataFrame.\n",
        "\n",
        "*Supervised* machine learning techniques involve in training a machine learning model that utilizes a set of *features* to predict a *label* using a dataset that includes already-known label values. This can be mathematically formulated as\n",
        "$$y = f([x_1, x_2, x_3, ...]),$$\n",
        "where $f$ represents a function that maps the features to the label.\n",
        "\n",
        "*Classification* is a form of supervised machine learning in which you train a model to use the features (the ***x*** = $[x_1, x_2, x_3, ...]$ values in our function) to predict a label (***y***) that calculates the probability of the observed case belonging to each of a number of possible classes, and predicting an appropriate label. The simplest form of classification is *binary* classification, in which the label is 0 or 1, representing one of two classes; for example, \"True\" or \"False\"; \"Risk\" or \"No-risk\"; \"Profitable\" or \"Non-Profitable\"; and so on.\n",
        "\n",
        "In this tutorial, we shall use the Breast Cancer Wisconsin (Diagnostic) Dataset, extracted from [kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). The goal of this dataset is to predict whether the cancer of patient is benign or malignant. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image and the 3-dimensional space that it occupies (K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34).\n",
        "\n",
        "Contents:\n",
        "- Explore and preprocess data\n",
        "- Split data into training data and test data\n",
        "- Train classification models using **scikit-learn** machine learning models\n",
        "- Save your model and inference new cases.\n",
        "- Appendix 1: Other file formats\n",
        "\n",
        "What you will learn:\n",
        "- Exploring and preprocessing data for training classification machine learning models.\n",
        "- Explore the different off-the-shelf classification machine learning models of **scikit-learn**.\n",
        "- Save the trained machine learning model and import it to make new predictions.\n",
        "\n",
        "\n",
        "Source:\n",
        "- [Microsoft's ml-basics tutorials](https://github.com/MicrosoftDocs/ml-basics)\n",
        "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
        "- [Matplotlib documentation](https://matplotlib.org/3.3.2/contents.html)\n",
        "- [User guide of Scikit-learn](https://scikit-learn.org/stable/user_guide.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK-stGKM75J4"
      },
      "source": [
        "## Explore and preprocess data\n",
        "\n",
        "Let us import the Breast Cancer Wisconsin Dataset. The dataset is saved in the folder *online-data* in *csv-format*. This is a common data format where the information is delimited using a symbol such as **,** or **;**.\n",
        "\n",
        "To import this data as a Pandas DataFrame into the memory of Python, the **read_csv** method can be used from the Pandas package. In this method, you need to provide which **delimiter** that is used in the dataset and whether a **header** is present. The header can contain schema information about what the numbers of the data represents. More information on Pandas DataFrame can be found in the [Pandas documentation](https://pandas.pydata.org/docs/).\n",
        "\n",
        "Remark:\n",
        "- To import data from other file formats, please look into Appendix 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZDKjWnl75J5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load the training dataset\n",
        "data = pd.read_csv('wisconsin_data.csv', delimiter=',', header='infer')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rB1oAFW75J7"
      },
      "source": [
        "We observe that we have data on 569 patients and that the first two columns contains information on\n",
        "- ID number of the patient\n",
        "- Cancer Diagnosis (M = malignant, B = benign).\n",
        "\n",
        "Also, ten real-valued features are computed for each cell nucleus:\n",
        "- Radius (mean of distances from center to points on the perimeter)\n",
        "- Texture (standard deviation of gray-scale values)\n",
        "- Perimeter\n",
        "- Area\n",
        "- Smoothness (local variation in radius lengths)\n",
        "- Compactness (perimeter^2 / area - 1.0)\n",
        "- Concavity (severity of concave portions of the contour)\n",
        "- Concave points (number of concave portions of the contour)\n",
        "- Symmetry\n",
        "- Fractal dimension (\"coastline approximation\" - 1).\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDsBZ5RT75J8"
      },
      "source": [
        "The first step in any machine learning project is to explore the data that you will use to train a model. The goal of this exploration is to try to understand the relationships between its attributes; in particular, any apparent correlation between the *features* and the *label* your model will try to predict. This may require some work\n",
        "- to detect and fix issues in the data (such as dealing with missing values, errors, or outlier values),\n",
        "- deriving new feature columns by transforming or combining existing features (a process known as *feature engineering*),\n",
        "- *normalizing* numeric features (values you can measure or count) so they're on a similar scale,\n",
        "- and *encoding* categorical features (values that represent discrete categories) as numeric indicators.\n",
        "\n",
        "For example, we observe that the last column of the dataset contains missing values from a mistake when importing the data. Also, the patient *id* cannot possibly predict the diagnosis label. Therefore, we will remove the first and last column using the following code cell. This can be done by using the **iloc** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXeZrFjm75J8"
      },
      "outputs": [],
      "source": [
        "# Remove the first and last column\n",
        "data2 = data.iloc[:, 1:32]\n",
        "data2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q5QlM1S75J9"
      },
      "source": [
        "We can visualize the distribution of the features of the dataset using a boxplot, sorted by each value of the label. Let us do this only for the mean values of the features,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qy490ykQ75J9"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Defining the features to visualize\n",
        "features = [\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\"]\n",
        "\n",
        "# Visualize using the boxplot method of matplotlib, sorted by the label values.\n",
        "for col in features:\n",
        "    data2.boxplot(column=col, by='diagnosis', figsize=(6,5))\n",
        "    plt.title(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTv-RaNi75J-"
      },
      "source": [
        "This is useful information. We observe that *radius_mean*, *texture_mean*, *perimeter_mean*, *area_mean*, *smoothness_mean*, *compactness_mean*, *concavity_mean* and *concave points_mean* show a difference in its distribution when the diagnosis is benign compared to when the diagnosis is malignant (the median of these mean features are higher when the diagnosis is malignant). Thus, we can be convinced that these features can be useful when predicting the diagnosis label. For *summetry_mean* and *fractal_dimension_mean*, this is not so obvious.\n",
        "\n",
        "This analysis can also be repeated for the ommited features of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9GpIOwI75J-"
      },
      "source": [
        "## Split data into training data and test data\n",
        "\n",
        "Let us now do prepare the dataset for training a machine learning model. We can split the dataset into a dataset with the features ***X*** and the label label ***y***, by locating their column numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0tPYk9E75J-"
      },
      "outputs": [],
      "source": [
        "# Split by features and label\n",
        "features_columns = range(1, data2.shape[1])\n",
        "label_column = 0\n",
        "X, y = data2.iloc[:, features_columns], data2.iloc[:, label_column]\n",
        "\n",
        "# Check the results\n",
        "for i in range(0,4):\n",
        "    print(\"Patient\", str(i+1), \"\\n  Features:\",list(X.iloc[i]), \"\\n  Label:\", y.iloc[i], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIb3X5f75J-"
      },
      "source": [
        "In machine learning, we construct a training dataset and a test dataset. The training dataset is, as the name suggests, for optimizing the untrained machine learning model into a machine learning model that recognizes the underlying relations and patterns of the dataset. The model is said to be *fitted* to the dataset. However, to evaluate the performance of the trained model, we measure its performance on a separate dataset, the test dataset.\n",
        "\n",
        "In the python **scikit-learn** package, we can use a **train_test_split** method that ensures we get a statistically random split of training and test data. We'll use that to split the data into 80% for training and hold back 20% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFYaBL4475J_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data 70%-30% into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l39szqCo75J_"
      },
      "source": [
        "## Train classification models using **scikit-learn** machine learning models\n",
        "\n",
        "One of the machine learning models that can be used for this classification dataset is the off-the-shelf *Logistic Regression* model of **scikit-learn** package. This model asks for a *regularization* parameter *C*. Without diving too much into the mathematics, *C* helps to generalize the model and avoids the phenomenon of *overfitting* to the training data.\n",
        "\n",
        "Data Scientist refer to parameters such as *C* as a *hyperparameter*, a number that you have to provide to the model, before it trains its *parameters* (the unknown numbers of the model). For simplicity, we shall fix *C* to a chosen number. In practice, it is best to try a few hyperparameter values and optimize for the best trained model. The Logistic Regression model can be *fitted* by calling its **fit** method, like this,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ4ZxBD775J_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Set regularization hyperparameter\n",
        "C = 100\n",
        "\n",
        "# train a logistic regression model on the training set\n",
        "model_log = LogisticRegression(C=C, solver=\"liblinear\").fit(X_train, y_train)\n",
        "print(model_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAltFcs575J_"
      },
      "source": [
        "Now that we have a trained model, we can use it to predict our test dataset using its **predict** method, like this,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfBnfC3d75J_"
      },
      "outputs": [],
      "source": [
        "predictions = model_log.predict(X_test)\n",
        "\n",
        "print('Predicted labels: ', predictions)\n",
        "print('Actual labels:    ', y_test.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzC_iE9e75J_"
      },
      "source": [
        "## Classification metrics\n",
        "\n",
        "We could compare each label value that was predicted with the actual label value, but that would be time consuming and not a good way to quantify the performance of the trained model. Several machine learning model metrics for classification to quantify the performance of the trained model are:\n",
        "- *Accuracy*: What proportion of the labels did the model predict correctly?\n",
        "- *Precision*: Of the predictons the model made for this class, what proportion were correct?\n",
        "- *Recall*: Out of all of the instances of this class in the test dataset, how many did the model identify?\n",
        "- *F1-Score*: An average metric that takes both precision and recall into account.\n",
        "- *Support*: How many instances of this class are there in the test dataset?\n",
        "\n",
        "For the accuracy metric, we can use the **accuracy_score** method of the **scikit-learn** package. For the other metrics, we can use the **classification_report** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7p9Caqd75KA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
        "print(\"Classification report: \\n\", classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Km3pV375KA"
      },
      "source": [
        "From these numbers we can make some statements, such as:\n",
        "- \"From all the patients that have cancer diagnosis benign, 94% of them are classified correcly using the trained model.\" (from the recall of benign diagnosis)\n",
        "- \"From all the malignant cancer diagnosis of the trained model, 92% of them are correcly classified.\" (from the precision of the malignant diagnosis)\n",
        "\n",
        "These statements are useful when reporting the performance of the trained machine learning model (e.g. machine learning applications in the public health sector).\n",
        "\n",
        "Mathematically, the precision and recall are calculated using the following quantities:\n",
        "\n",
        "* *True Positives*: The predicted label and the actual label are both 1.\n",
        "* *False Positives*: The predicted label is 1, but the actual label is 0.\n",
        "* *False Negatives*: The predicted label is 0, but the actual label is 1.\n",
        "* *True Negatives*: The predicted label and the actual label are both 0.\n",
        "\n",
        "In our dataset, *1* could correspond to malignant, while *0* to benign. We could visualize these quantities in a *confusion matrix*. This can be easily calculated using the **confusion_matrix** method of the **scikit-learn** package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPPajtfH75KB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate and display the confusion matrix\n",
        "m = confusion_matrix(y_test, predictions)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRU5WBSN75KB"
      },
      "source": [
        "We can also visualize this confusion matrix using the **plot_confusion_matrix** of **scikit-learn** package,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP4u50mS75KC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "# Plot the confusion matrix\n",
        "m = plot_confusion_matrix(model_log, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y3yxRHz75KC"
      },
      "source": [
        "We observe that the values of the confusion matrix are color-coded and a corresponding legend is provided.\n",
        "\n",
        "Statistical machine learning algorithm, such as *LogisticRegression* work with *probability*. The predicted class labels using the trained model are assigned to a certain value based on a given threshold. For example, A threshold of 0.5 will cause that the label 1 is predicted when *P(y) > 0.5* or the label 0 when *P(y) <= 0.5*, where *P(y)* denotes the probability that is returned by the model.\n",
        "\n",
        "These probailities can be returned explicitly using the **predict_proba** method of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5qkmPHm75KC"
      },
      "outputs": [],
      "source": [
        "y_prob = model_log.predict_proba(X_test)\n",
        "print(y_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2SWAaI975KC"
      },
      "source": [
        "We observe that for the first test data instance, The trained model predict a 99.79% probability that it has label 'malignant'.\n",
        "\n",
        "A consequence is, depending on the given threshold, different classes can be assigned on the final classification predictions. A way to quantify the performance of the trained classification model, regardless of the given threshold, is by using a *received operator characteristic (ROC) chart*, which plots the *true positive rate* (TPR) against the *false positive rate* (FPR):\n",
        "\n",
        "$$ TPR = \\frac{TP}{TP + FN},$$\n",
        "\n",
        "$$ FPR = \\frac{FP}{FP + TN}.$$\n",
        "\n",
        "This can be plotted using the **roc_curve** of the **scikit-learn** package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ-Qi_iS75KC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Replace the y_test values into 1s and 0s using a dictionary\n",
        "di = {\"M\": 1, \"B\": 0}\n",
        "y_test2 = y_test.map(di)\n",
        "\n",
        "# Calculate ROC curve, select the 1 convention of y_prob (in this case, 1 corresponds to malignant)\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, y_prob[:,1])\n",
        "\n",
        "# Plot ROC curve\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve -- LogisticRegression')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H51H8LT75KC"
      },
      "source": [
        "The curve on the *ROC-curve* represent the TPR and the FPR of every possible chosen threshold for the trained model. The straight line is a reference and represent a model that guess the label classes randomly (we want to perform better than this). The more the ROC-cure is curved above this reference line, the better the model. For more info, please visit this [wikipedia page](https://en.wikipedia.org/wiki/Receiver_operating_characteristic).\n",
        "\n",
        "A performance metric from the ROC-curve is to calculate the area under the curve (AUC), which is a number between 0 and 1. The higher this number, the better your trained model regardless of the chosen threshold. This can be calculated using the **roc_auc_score** method from **scikit-learn**. We shall use this method to get the AUC and save it in a table for later reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv_Z5KRM75KC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate AUC\n",
        "auc = roc_auc_score(y_test2,y_prob[:,1])\n",
        "\n",
        "# Put it in a table for later reference\n",
        "metrics = pd.DataFrame(index = [\"AUC\"], columns = [\"LogisticRegression\"])\n",
        "metrics.iloc[0,0] = auc\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsUAYZv675KD"
      },
      "source": [
        "## Try other classification models\n",
        "\n",
        "Now let us try a different algorithm other than *LogisticRegression*. There are many kinds of classification algorithm we could try, such as:\n",
        "\n",
        "- *Support Vector Machine (SVM) algorithms*: Algorithms that define a *hyperplane* that separates classes.\n",
        "- *Tree-based algorithms*: Algorithms that build a decision tree to reach a prediction\n",
        "- *Ensemble algorithms*: Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n",
        "\n",
        "Let us try a classification model using a Support Vector Machine algorithm. For this algorithm, we must provide a *kernel function*. It can be seen as another hyperparameter that you have to provide to the model before training. For more details, see the [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/svm.html).\n",
        "\n",
        "For simplicity let us train a linear SVM (with a linear kernel), plot the ROC-curve and store its AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb_fh9EW75KD"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Set regularization hyperparameter\n",
        "C = 100\n",
        "\n",
        "# train a linear SVM model on the training set\n",
        "model = LinearSVC(C=C).fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "# Calculate AUC and store\n",
        "y_prob = model.decision_function(X_test)\n",
        "auc = roc_auc_score(y_test2, y_prob)\n",
        "\n",
        "# Plot ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, y_prob)\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve -- LinearSVC')\n",
        "plt.show()\n",
        "\n",
        "# Concatinate AUC\n",
        "m = pd.Series([auc])\n",
        "m.index = [\"AUC\"]\n",
        "metrics = pd.concat([metrics, m.rename(\"LinearSVC\")], axis=1)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sghbyvx975KD"
      },
      "source": [
        "As an alternative, there's a category of algorithms for machine learning that uses a tree-based approach in which the features in the dataset are examined in a series of evaluations, each of which results in a *branch* in a *decision tree* based on the feature value. At the end of each series of branches are leaf-nodes with the predicted label value based on the feature values.\n",
        "\n",
        "It's easiest to see how this works with an example. Let us train a Decision Tree classification model using the Wisconsin Breast Cancer data. After training the model, the code below will print the model definition and a text representation of the tree it uses to predict label values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoR_gI9k75KD"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "# train a Decision Tree Classifier model on the training set\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "print(model, \"\\n\")\n",
        "\n",
        "# Visualize the model tree\n",
        "tree = export_text(model)\n",
        "print(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMImRjYn75KD"
      },
      "source": [
        "Let us calculate the ROC-curve and store its AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of5VVKvD75KD"
      },
      "outputs": [],
      "source": [
        "# Calculate AUC and store\n",
        "y_prob = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test2, y_prob[:,1])\n",
        "\n",
        "# Plot ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, y_prob[:,1])\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve -- DecisionTreeClassifier')\n",
        "plt.show()\n",
        "\n",
        "# Concatinate AUC\n",
        "m = pd.Series([auc])\n",
        "m.index = [\"AUC\"]\n",
        "metrics = pd.concat([metrics, m.rename(\"DecisionTreeClassifier\")], axis=1)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkRbb-bO75KD"
      },
      "source": [
        "Finally, we will repeat the process with a model using an *ensemble* algorithm named *Random Forest* that combines the outputs of multiple random decision trees (for more details, see the [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKfnoXoi75KD"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Provide number of estimator (hyperparameter)\n",
        "n = 100\n",
        "\n",
        "# train a linear SVM model on the training set\n",
        "model = RandomForestClassifier(n_estimators=n).fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "# Calculate AUC and store\n",
        "y_prob = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test2, y_prob[:,1])\n",
        "\n",
        "# Plot ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test2, y_prob[:,1])\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve -- RandomForestClassifier')\n",
        "plt.show()\n",
        "\n",
        "# Concatinate AUC\n",
        "m = pd.Series([auc])\n",
        "m.index = [\"AUC\"]\n",
        "metrics = pd.concat([metrics, m.rename(\"RandomForestClassifier\")], axis=1)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy6ZxyTr75KE"
      },
      "source": [
        "## Save your model and inference new cases\n",
        "\n",
        "We have tried several machine learning models for our regression dataset.\n",
        "Let us save the *LogisticRegression* model, as a local file.\n",
        "\n",
        "This can be done like this,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyhyLzer75KE"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model as a pickle file\n",
        "filename = 'model.pkl'\n",
        "joblib.dump(model_log, filename)\n",
        "\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEvj7ddN75KH"
      },
      "source": [
        "Now, we can load it whenever we need it, and use it to predict labels for new data. This is often called *scoring* or *inferencing*.\n",
        "\n",
        "The scenario might be that measurements of a cell nucleus of a new patient has been measured, and we want to predict whether the tumor of the patient is benign or malignant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auehfGm775KI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "# Create a numpy array containing the data on measurements of the cell nucleus\n",
        "X_new = np.array([[19.69, 21.25, 130.0, 1203.0, 0.1096, 0.1599, 0.1974, 0.1279, 0.2069, 0.0599, 0.7456, 0.7869, 4.585, 94.03, 0.00615, 0.0401, 0.03832, 0.02058, 0.0225, 0.004571, 23.57, 25.53, 152.5, 1709.0, 0.1444, 0.4245, 0.4504, 0.243, 0.3613, 0.0873]]).astype('float64')\n",
        "print ('New sample: {} \\n'.format(list(X_new[0])))\n",
        "\n",
        "# Use the model to predict type tumor\n",
        "result = loaded_model.predict(X_new)\n",
        "print('Prediction tumor type: {} \\n'.format(result[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws9h85DC75KI"
      },
      "source": [
        "## Further Readings\n",
        "\n",
        "Sources:\n",
        "- To learn more about Scikit-Learn, see the [Scikit-Learn documentation](https://scikit-learn.org/stable/user_guide.html).\n",
        "- To learn more about machine learning basics on other datasets, see the [Microsoft's ml-basics tutorials](https://github.com/MicrosoftDocs/ml-basics)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}